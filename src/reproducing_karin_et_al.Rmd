---
title: "Reproducing Karin et al's longitudal model of senescent cell growth"
output:
  html_document:
    df_print: paged
  pdf_document: default
params:
  data_dir: ../dat/
---

```{r include=FALSE}
library(brms)
library(dplyr)
library(foreach)
library(ggplot2)
library(ggpubr)
library(latex2exp)
library(purrr)
library(reshape2)
library(stringr)
library(tidyverse)

# Stan-specific stuff
library(bridgesampling)
library(rstan)
library(gridExtra)
rstan_options (auto_write = TRUE)
options (mc.cores = parallel::detectCores ())
set.seed(3) # for reproductibility
```
# Loading and visualizing the data
As our first step, we load the data we'll use to fit the 16 models described
in Karin et al (TODO: actual reference). To do so, we load the raw data
from their paper (used for their fig. 2) and transform it into a 3-column
dataframe indexed by mouse number and week of measurement taken.

```{r}
snc_counts_fname <- str_c(
  params$data_dir, "raw", "senescent_cells_and_the_dynamics_of_aging__fig_2.csv",
  sep="/"
)
raw_snc_counts <- read.csv(snc_counts_fname, header=TRUE) %>%
  drop_na()
snc_counts <- melt(
  data = raw_snc_counts, 
  id.vars = "mouse.week", 
  measure.vars = c(
    "X8", "X16", "X24", "X32", "X40", "X48", "X56", "X64", "X72", "X80"
  ),
  value.name = "TBL_x_10_5"
)
snc_counts <- snc_counts %>%
  rename(week = "variable", mouse = "mouse.week")
snc_counts$week <- map_int(snc_counts$week, function (week) { return(as.integer(substr(week, 2, str_length(week)))) })
max(snc_counts$mouse)
```
Now we're going to reproduce Karin et al's fig. 2a, since it doesn't require any
model-fitting, although we won't do the nice grey shading they did for now...
```{r}
ggplot(
  data = snc_counts, 
  aes(x = week, y = TBL_x_10_5, color = mouse, group = mouse)
) +
  xlab("Week") + ylab(TeX("$ TBL \\times 10^5 $")) +
  scale_color_gradientn(colours = rainbow(5)) + geom_line() + geom_point()
```

Next we're going to replicate the first part of Karin et al's fig 2c, which
shows the mean and standard deviation of normalized senescent cell counts
at each week time point.

To normalize senescent cell counts, we adjust all counts to make the mean
abundance across the first three measured time points -- 8, 16, 24 -- equal 1.
To do so, we set
$$
\beta = \frac{1}{3n} \sum_{i=1}^n \sum_{j \in 8, 16, 24} c_{ij} = 1
$$
and divide all counts by it. In other words, normalize by the mean abundance
from the first three weeks of data.

```{r}
norm_const <- mean(
  snc_counts[snc_counts$week %in% c(8, 16, 24),]$TBL_x_10_5, na.rm = T
)
snc_counts$norm_abundance <- snc_counts$TBL_x_10_5 / norm_const
mean_abundances <- aggregate(
  snc_counts$norm_abundance, list(snc_counts$week), mean, na.rm = T
)$x
stddev_abundances <- aggregate(
  snc_counts$norm_abundance, list(snc_counts$week), sd, na.rm = T
)$x
mean_stddev_abundances <- data.frame(
  mean = mean_abundances,
  stddev = stddev_abundances,
  week = unique(snc_counts$week)
)
p <- ggplot(mean_stddev_abundances, aes(x=week, y=mean)) + geom_point() +
    geom_errorbar(aes(ymin=mean-stddev/2, ymax=mean+stddev/2), width=.2,
                 position=position_dodge(0.05))
print(p)
```
Notably our standard deviation bars seem larger than whatever Karin et al show
in their full version of this figure (fig. 2c), but we seem to reproduce their
standard error values based on their display of them in fig. 2d.

## Fitting the SR model
As a way to check we haven't missed something integral to Karin et al's work,
we're going to fit a Bayesian version of their SR (Saturated-Removal) model
and verify that we (hopefully) approximately reproduce their predictive
distribution. 

Since they did maximum likelihood estimation (with a grid search I'd add)
whereas we're fitting a full posterior distribution with close-to-noninformative
prior, we don't expect exact matching. Because the likelihood includes an ODE,
analytically showing the data dominates the prior goes beyond my abilities, but
intuitively I expect the posterior predictive distribution to have approximately
the same mean as theirs with wider error bars.

```{r}
# Time series of SnC counts
mice <- unique(snc_counts$mouse)
weeks <- unique(snc_counts$week)
n_mice <- length(mice)
n_weeks <- length(weeks)
print(n_mice)
snc_abundance <- matrix(nrow = n_mice, ncol=n_weeks)
for (m in 1:n_mice) {
  for (t in 1:n_weeks) {
    week <- weeks[t]
    mouse <- mice[m]
    mouse_week_index <- which(snc_counts$mouse == mouse & snc_counts$week == week)[1]
    snc_abundance[m, t] <- snc_counts$norm_abundance[mouse_week_index]
  }
}

# times
t <- seq(0, n_weeks * 8, by = 8) # 8 hard-coded to match data
t0 = 0
t <- t[-1]

# initial conditions
y0 = c(1)
dim(y0) <- (1)

# data for Stan
data_snc <- list(n_weeks = n_weeks, n_mice = n_mice, y0 = y0, t0 = t0, ts = t, cells = snc_abundance)

# number of MCMC steps
niter <- 2000
```


```{r}
model <- stan_model("snc_sr_model.stan")
fit_snc_sr_model <- sampling(
  model,
  data = data_snc,
  iter = niter,
  chains = 4
)
```
## Diagnosing model fit
Inspired by [this Stan case study](https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html#3_scaling_up_ode-based_models)
and general best practices for checking the results of HMC, let's do some
posterior checks to verify HMC ended up sampling a reasonable approximation
of the true posterior. First, we can look at \( \hat{R} \) and \( n_{\text{eff}} \).
\( \hat{R} \) measures the level of agreement between our four independent
Markov chains. An \( \hat{R} \leq 1.01 \)
for a parameter implies close agreement between the chains, so it's great to see
that all of our parameters of interest have \( \hat{R} \)s of 1. 
$ n_{\text{eff}} $, is a proxy measure of __effective__ sample size, which we
can think of as sample size adjusted down as a function of how correlated 
different samples from the posterior are. Again, our \( n_{\text{eff}} \)s all
seem pretty good given the number of samples we draw.

```{r}
pars=c('eta', 'beta', 'sigma', 'lp__', 'log_likelihood')
print(fit_snc_sr_model, pars = pars, digits_summary = 6)
```

```{r}
pairs(fit_snc_sr_model, pars=pars)
```


Next, we can look at density plots for our posterior distribution to verify
that the posterior distributions look uni-modal (assuming that's what we want)
and relatively similar across chains. In this case, they do!

```{r}
stan_dens(fit_snc_sr_model, pars = pars, separate_chains = TRUE)
```

Now we can actually evaluate our SR model with respect to data. As a first-pass
evaluation, we'll basically replicate Karin et al's fig. 2c with only
predictions from the SR model included for now. As the graph shows, our model
seems to capture the progression of SnC abundance growth as well or, in my
opinion, better than the max. likelihood equivalent in Karin et al. Our
posterior predictive means -- as we'd hope -- look almost identical to
Karin et al's but our 95% predictive intervals capture the variance
(as measured by standard deviation) of the individual mouse estimates better 
than their SR model does.

```{r}
snc_sr_counts_pred <- cbind(
  as.data.frame(
    summary(
      fit_snc_sr_model, pars = "pred_cells_means", 
      probs = c(0.05, 0.5, 0.95)
    )$summary
  ), 
  t, 
  mean_abundances,
  stddev_abundances
)
colnames(snc_sr_counts_pred) <- make.names(colnames(snc_sr_counts_pred)) # to remove % in the col names
ggplot(snc_sr_counts_pred, mapping = aes(x = t)) +
  geom_ribbon(aes(ymin = X5., ymax = X95.), fill = "orange", alpha = 0.6) +
  geom_line(mapping = aes(x = t, y = X50.)) + 
  geom_point(mapping = aes(y = mean_abundances)) +
  geom_errorbar(
    aes(
      ymin=mean_abundances - stddev_abundances/2,
      ymax=mean + stddev_abundances/2
    ),
    width=.2,
    position=position_dodge(0.05)
  ) +
  scale_x_continuous(name = "Week", breaks=t, labels=t, limits = c(8, 80)) +
  labs(x = "Week", y = "SnC (normalized)")
```


## Fitting the USR model
Now, to enable us to validate that our comparison produces similar qualitative
results to the original paper's, we're going to fit a second model. The biggest
difference between this model and the first model is that lack of a saturated
removal term. The saturated removal term in the prior model is intended to
capture the phenomenon in which senescent cells become so abundant
that the immune system becomes unable to efficiently remove them.
```{r}
model <- stan_model("snc_usr_model.stan")
fit_usr_model <- sampling(
  model,
  data = data_snc,
  iter = niter,
  chains = 4
)
```


## Diagnosing model fit
We look at the same diagnostics as previously and again find that our
chains have mixed and our \( n_{\text{eff}} \)s seem reasonable. Our
posterior densities also again look (mostly) unimodal.

```{r}
pars=c('eta', 'beta', 'sigma', 'log_likelihood', 'lp__')
print(fit_usr_model, pars = pars)
```

```{r}
pairs(fit_usr_model, pars = pars)
```

```{r}
stan_dens(fit_usr_model, pars = pars, separate_chains = TRUE)
```

Finally, we can again look at how well our posterior intervals capture
the true data points. To make qualitative comparison with the prior model easier
we plot both model's fits on the graph.

```{r}
snc_usr_counts_pred <- cbind(
  as.data.frame(
    summary(
      fit_usr_model, pars = "pred_cells_means", 
      probs = c(0.05, 0.5, 0.95)
    )$summary
  ), 
  t, 
  mean_abundances,
  stddev_abundances
)
colnames(snc_usr_counts_pred) <- make.names(colnames(snc_usr_counts_pred)) # to remove % in the col names
p_usr <- ggplot(snc_usr_counts_pred, mapping = aes(x = t)) +
  geom_ribbon(aes(ymin = X5., ymax = X95.), fill = "blue", alpha = 0.6) +
  geom_line(mapping = aes(x = t, y = X50.)) + 
  geom_point(mapping = aes(y = mean_abundances)) +
  geom_errorbar(
    data = snc_sr_counts_pred, 
    aes(
      ymin=mean_abundances - stddev_abundances/2,
      ymax=mean + stddev_abundances/2,
    ),
    width=.2,
    position=position_dodge(0.05),
  ) +
  labs(title = "Unsaturated Removal Model Predictions", x = "Week", y = "SnC (normalized)", color = "name")

p_sr <- ggplot(snc_sr_counts_pred, mapping = aes(x = t)) +
  geom_ribbon(aes(ymin = X5., ymax = X95.), fill = "orange", alpha = 0.6) +
  geom_line(mapping = aes(x = t, y = X50.)) + 
  geom_point(mapping = aes(y = mean_abundances)) +
  geom_errorbar(
    aes(
      ymin=mean_abundances - stddev_abundances/2,
      ymax=mean + stddev_abundances/2
    ),
    width=.2,
    position=position_dodge(0.05)
  ) +
  scale_x_continuous(name = "Week", breaks=t, labels=t, limits = c(8, 80)) +
  labs(title = "Saturated Removal Model Predictions", x = "Week", y = "SnC (normalized)", color = "name")
ggarrange(p_usr, p_sr)
```

Interestingly, our USR graph looks much better than the one in the Alon paper
with respect to matching the observations.

Fortunately, since we're being Bayesian about all this, we can improve over
the Alon paper's original model comparison by using Bayes Factors to compute
the odds ratio of our two models' marginal likelihoods (assuming equal
prior probability between the two). 

As we expected based on Karin et al, the SNC SR model is deemed much more
probable than the USR model. Note that the Bayes factor measures, assuming
our two models are denoted \( \mathcal{M}_1 \), \( \mathcal{M}_2 \):
$$
\frac{P(\mathcal{M}_1 \mid \text{data})}{P(\mathcal{M}_2 \mid \text{data})},
$$
so this posterior odds ratio accounts for the relative sizes of the parameter
spaces used by the two models.

```{r}
fit_snc_sr_model.bridge <- bridge_sampler(fit_snc_sr_model, silent = T)
fit_usr_model.bridge <- bridge_sampler(fit_usr_model, silent = T)
bayes_factor(fit_snc_sr_model.bridge, fit_usr_model.bridge)
post_prob(fit_snc_sr_model.bridge, fit_usr_model.bridge)
```

# Senescence-Induced Senescence Model
The SIS model seeks to test a hypothesis that senescent cells can be coarsely
broken down into long-lived and short-lived senescent cells and that these
long-lived cells can induce healthy cells to become (short-lived type) 
senescent.

In order to test this, we add an additional term \( \alpha \) to model
the 



